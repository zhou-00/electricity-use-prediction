{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, max_error, r2_score\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adamax, Adagrad, Adadelta, Nadam\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM LOSS FUNCTIONS (not built into default Keras API)\n",
    "\n",
    "# SOURCE:\n",
    "# Simple regression example for Keras (v2.2.2) with Boston housing data\n",
    "# @author: tobigithub\n",
    "# Created on Wed Aug 15 18:44:28 2018\n",
    "\n",
    "\n",
    "# root mean squared error (rmse) \n",
    "def rmse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "# mean squared error (mse) \n",
    "def mse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "# coefficient of determination (R^2) \n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "energyFrame = pd.read_csv(\"UCI_data.csv\")\n",
    "energy = energyFrame.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "np.random.seed(12345)\n",
    "rn.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X = energy[:, 1:(energy.shape[1]-1)]\n",
    "y = energy[:, -1]\n",
    "X_train_outer, X_test_outer, y_train_outer, y_test_outer = train_test_split(X, y, test_size=0.2)\n",
    "n_cols = X_train_outer.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search hyperparameters: batch size and number of epochs\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation=\"relu\", input_shape=(n_cols,)))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(optimizer=\"adam\", loss = 'mean_squared_error', metrics=[mse])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "pipe = Pipeline([(\"scale\", MinMaxScaler()),(\"model\", model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 26.8min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed: 65.8min remaining:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 107.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15788/15788 [==============================] - 7s 448us/step - loss: 12705.6686 - mse: 12705.6484\n",
      "Epoch 2/500\n",
      "15788/15788 [==============================] - 8s 484us/step - loss: 11125.1434 - mse: 11125.1504\n",
      "Epoch 3/500\n",
      "15788/15788 [==============================] - 4s 249us/step - loss: 11066.2672 - mse: 11066.2715\n",
      "Epoch 4/500\n",
      "15788/15788 [==============================] - 3s 190us/step - loss: 11011.4497 - mse: 11011.4316\n",
      "Epoch 5/500\n",
      "15788/15788 [==============================] - 4s 249us/step - loss: 10958.0975 - mse: 10958.1084\n",
      "Epoch 6/500\n",
      "15788/15788 [==============================] - 4s 262us/step - loss: 10903.5418 - mse: 10903.5391\n",
      "Epoch 7/500\n",
      "15788/15788 [==============================] - 5s 322us/step - loss: 10851.6106 - mse: 10851.5986\n",
      "Epoch 8/500\n",
      "15788/15788 [==============================] - 3s 201us/step - loss: 10797.4467 - mse: 10797.4619\n",
      "Epoch 9/500\n",
      "15788/15788 [==============================] - 5s 339us/step - loss: 10746.5924 - mse: 10746.5820\n",
      "Epoch 10/500\n",
      "15788/15788 [==============================] - 3s 221us/step - loss: 10693.5780 - mse: 10693.5781\n",
      "...\n",
      "...\n",
      "...\n",
      "Epoch 490/500\n",
      "15788/15788 [==============================] - 8s 515us/step - loss: 8980.5883 - mse: 8980.5840\n",
      "Epoch 491/500\n",
      "15788/15788 [==============================] - 8s 498us/step - loss: 8978.3828 - mse: 8978.3975\n",
      "Epoch 492/500\n",
      "15788/15788 [==============================] - 7s 443us/step - loss: 8981.3927 - mse: 8981.3945 0s - loss: 8892.2358 - mse\n",
      "Epoch 493/500\n",
      "15788/15788 [==============================] - 7s 426us/step - loss: 8978.3908 - mse: 8978.4014 5s - ETA: 1s -\n",
      "Epoch 494/500\n",
      "15788/15788 [==============================] - 7s 432us/step - loss: 8971.2857 - mse: 8971.2852\n",
      "Epoch 495/500\n",
      "15788/15788 [==============================] - 7s 440us/step - loss: 8969.1874 - mse: 8969.2041\n",
      "Epoch 496/500\n",
      "15788/15788 [==============================] - 8s 480us/step - loss: 8969.3163 - mse: 8969.3203\n",
      "Epoch 497/500\n",
      "15788/15788 [==============================] - 7s 446us/step - loss: 8982.3641 - mse: 8982.3633\n",
      "Epoch 498/500\n",
      "15788/15788 [==============================] - 6s 411us/step - loss: 8976.8010 - mse: 8976.7969: 6s - loss: 9864.2557 - mse: 9864.258 - ETA: 7s - loss: 988 - ETA:\n",
      "Epoch 499/500\n",
      "15788/15788 [==============================] - 7s 443us/step - loss: 8980.2844 - mse: 8980.2920\n",
      "Epoch 500/500\n",
      "15788/15788 [==============================] - 7s 466us/step - loss: 8976.4628 - mse: 8976.4629 0s - loss: 9125.7832 - \n",
      "Best parameters: -9387.301086 using {'model__epochs': 500, 'model__batch_size': 5}\n",
      "Mean test score: -9596.318692, Std test score: 717.504311 with: {'model__epochs': 100, 'model__batch_size': 5}\n",
      "Mean test score: -10981.558695, Std test score: 787.401826 with: {'model__epochs': 25, 'model__batch_size': 50}\n",
      "Mean test score: -9473.746881, Std test score: 758.600109 with: {'model__epochs': 500, 'model__batch_size': 25}\n",
      "Mean test score: -9986.960862, Std test score: 765.051480 with: {'model__epochs': 100, 'model__batch_size': 50}\n",
      "Mean test score: -10075.522709, Std test score: 791.398500 with: {'model__epochs': 50, 'model__batch_size': 10}\n",
      "Mean test score: -10221.037396, Std test score: 766.353051 with: {'model__epochs': 25, 'model__batch_size': 5}\n",
      "Mean test score: -9750.674546, Std test score: 761.853036 with: {'model__epochs': 100, 'model__batch_size': 10}\n",
      "Mean test score: -9429.535057, Std test score: 812.363515 with: {'model__epochs': 250, 'model__batch_size': 10}\n",
      "Mean test score: -9387.301086, Std test score: 737.434302 with: {'model__epochs': 500, 'model__batch_size': 5}\n",
      "Mean test score: -9834.546221, Std test score: 787.292637 with: {'model__epochs': 100, 'model__batch_size': 25}\n"
     ]
    }
   ],
   "source": [
    "# search hyperparameters: batch size and number of epochs\n",
    "\n",
    "batch_size = [5, 10, 25, 50]\n",
    "epochs = [25, 50, 100, 250, 500]\n",
    "param_dict = dict(model__batch_size=batch_size, model__epochs=epochs)\n",
    "grid = RandomizedSearchCV(estimator=pipe, param_distributions=param_dict, n_jobs=-1, cv=3, verbose=10) # n_jobs=-1 : run all processes in parallel\n",
    "grid_result = grid.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "print(\"Best parameters: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"Mean test score: %f, Std test score: %f with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUNE LEARNING RATE\n",
    "# this depends on which optimizer is chosen / depends on results of above tuning mechanism\n",
    "\n",
    "def create_model(learning_rate=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation=\"relu\", input_shape=(n_cols,)))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss = 'mean_squared_error', metrics=[mse])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs=500, batch_size=5, verbose=1)\n",
    "pipe = Pipeline([(\"scale\", MinMaxScaler()),(\"model\", model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 246.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15788/15788 [==============================] - 4s 228us/step - loss: 11233.1846 - mse: 11233.2031\n",
      "Epoch 2/500\n",
      "15788/15788 [==============================] - 3s 211us/step - loss: 10617.2452 - mse: 10617.2490\n",
      "Epoch 3/500\n",
      "15788/15788 [==============================] - 3s 218us/step - loss: 10311.3986 - mse: 10311.3975 0s - loss: 10646.0484 \n",
      "Epoch 4/500\n",
      "15788/15788 [==============================] - 4s 231us/step - loss: 10110.7112 - mse: 10110.7188\n",
      "Epoch 5/500\n",
      "15788/15788 [==============================] - 3s 212us/step - loss: 9963.4821 - mse: 9963.4697\n",
      "Epoch 6/500\n",
      "15788/15788 [==============================] - 3s 191us/step - loss: 9864.1623 - mse: 9864.1543\n",
      "Epoch 7/500\n",
      "15788/15788 [==============================] - 3s 192us/step - loss: 9793.9565 - mse: 9793.9521\n",
      "Epoch 8/500\n",
      "15788/15788 [==============================] - 3s 185us/step - loss: 9754.7608 - mse: 9754.7568\n",
      "Epoch 9/500\n",
      "15788/15788 [==============================] - 3s 189us/step - loss: 9683.1622 - mse: 9683.1494\n",
      "Epoch 10/500\n",
      "15788/15788 [==============================] - 3s 193us/step - loss: 9645.8865 - mse: 9645.9102\n",
      "...\n",
      "...\n",
      "...\n",
      "Epoch 490/500\n",
      "15788/15788 [==============================] - 3s 184us/step - loss: 8922.3529 - mse: 8922.3535\n",
      "Epoch 491/500\n",
      "15788/15788 [==============================] - 3s 184us/step - loss: 8916.1948 - mse: 8916.1953 0s - loss: 8915.2490 - mse: 8915.2\n",
      "Epoch 492/500\n",
      "15788/15788 [==============================] - 3s 182us/step - loss: 8917.8743 - mse: 8917.8750\n",
      "Epoch 493/500\n",
      "15788/15788 [==============================] - 3s 183us/step - loss: 8920.6658 - mse: 8920.6436\n",
      "Epoch 494/500\n",
      "15788/15788 [==============================] - 3s 184us/step - loss: 8935.5470 - mse: 8935.5420 1s - loss:\n",
      "Epoch 495/500\n",
      "15788/15788 [==============================] - 3s 212us/step - loss: 8924.4415 - mse: 8924.4482\n",
      "Epoch 496/500\n",
      "15788/15788 [==============================] - 3s 191us/step - loss: 8912.5226 - mse: 8912.5156\n",
      "Epoch 497/500\n",
      "15788/15788 [==============================] - 3s 183us/step - loss: 8929.1759 - mse: 8929.1592\n",
      "Epoch 498/500\n",
      "15788/15788 [==============================] - 3s 188us/step - loss: 8922.2510 - mse: 8922.2754\n",
      "Epoch 499/500\n",
      "15788/15788 [==============================] - 3s 182us/step - loss: 8906.9161 - mse: 8906.9189\n",
      "Epoch 500/500\n",
      "15788/15788 [==============================] - 3s 183us/step - loss: 8930.4265 - mse: 8930.4307\n",
      "Best: -9014.195436 using {'model__learning_rate': 0.01}\n",
      "-9198.298861 (655.965349) with: {'model__learning_rate': 0.001}\n",
      "-9014.195436 (787.387808) with: {'model__learning_rate': 0.01}\n",
      "-9297.634027 (762.081967) with: {'model__learning_rate': 0.1}\n",
      "-9602.858481 (874.751848) with: {'model__learning_rate': 0.25}\n",
      "-11042.695133 (871.722187) with: {'model__learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.001, 0.01, 0.1, 0.25, 0.5]\n",
    "param_grid = dict(model__learning_rate=learning_rate)\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=param_grid, n_jobs=-1, cv=3, verbose=10)\n",
    "grid_result = grid.fit(X_train_outer, y_train_outer)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUNE NETWORK WEIGHT INITIALISATION\n",
    "\n",
    "def create_model(init_mode=\"uniform\"):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, kernel_initializer=init_mode, activation=\"relu\", input_shape=(n_cols,)))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation=\"linear\"))\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=optimizer, loss = \"mean_squared_error\", metrics=[mse])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs=500, batch_size=5, verbose=1)\n",
    "pipe = Pipeline([(\"scale\", MinMaxScaler()),(\"model\", model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 172.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15788/15788 [==============================] - 3s 201us/step - loss: 11248.3981 - mse: 11248.3877\n",
      "Epoch 2/500\n",
      "15788/15788 [==============================] - 3s 204us/step - loss: 10620.2553 - mse: 10620.2637\n",
      "Epoch 3/500\n",
      "15788/15788 [==============================] - 3s 209us/step - loss: 10322.6671 - mse: 10322.6514\n",
      "Epoch 4/500\n",
      "15788/15788 [==============================] - 3s 204us/step - loss: 10121.3737 - mse: 10121.3691\n",
      "Epoch 5/500\n",
      "15788/15788 [==============================] - 3s 198us/step - loss: 9969.3277 - mse: 9969.3271\n",
      "Epoch 6/500\n",
      "15788/15788 [==============================] - 3s 207us/step - loss: 9855.0457 - mse: 9855.0615\n",
      "Epoch 7/500\n",
      "15788/15788 [==============================] - 3s 196us/step - loss: 9757.1346 - mse: 9757.1426A: 1s - loss: 10256.3197 - ms - ETA: 0s - loss: 10031.551\n",
      "Epoch 8/500\n",
      "15788/15788 [==============================] - 3s 190us/step - loss: 9691.2692 - mse: 9691.2656\n",
      "Epoch 9/500\n",
      "15788/15788 [==============================] - 3s 192us/step - loss: 9653.5027 - mse: 9653.5049\n",
      "Epoch 10/500\n",
      "15788/15788 [==============================] - 3s 194us/step - loss: 9629.1843 - mse: 9629.1865\n",
      "...\n",
      "...\n",
      "...\n",
      "Epoch 490/500\n",
      "15788/15788 [==============================] - 4s 240us/step - loss: 8909.7038 - mse: 8909.7061\n",
      "Epoch 491/500\n",
      "15788/15788 [==============================] - 3s 197us/step - loss: 8911.4420 - mse: 8911.4512\n",
      "Epoch 492/500\n",
      "15788/15788 [==============================] - 3s 205us/step - loss: 8909.4500 - mse: 8909.4551\n",
      "Epoch 493/500\n",
      "15788/15788 [==============================] - 4s 278us/step - loss: 8905.7477 - mse: 8905.7510\n",
      "Epoch 494/500\n",
      "15788/15788 [==============================] - 6s 349us/step - loss: 8933.1574 - mse: 8933.1514 0s - loss: 8984.3400 - ms\n",
      "Epoch 495/500\n",
      "15788/15788 [==============================] - 6s 396us/step - loss: 8936.5116 - mse: 8936.5195\n",
      "Epoch 496/500\n",
      "15788/15788 [==============================] - 6s 376us/step - loss: 8924.7181 - mse: 8924.7168\n",
      "Epoch 497/500\n",
      "15788/15788 [==============================] - 3s 204us/step - loss: 8903.7753 - mse: 8903.7783\n",
      "Epoch 498/500\n",
      "15788/15788 [==============================] - 3s 219us/step - loss: 8920.2064 - mse: 8920.1973\n",
      "Epoch 499/500\n",
      "15788/15788 [==============================] - 3s 221us/step - loss: 8912.0904 - mse: 8912.0859\n",
      "Epoch 500/500\n",
      "15788/15788 [==============================] - 4s 269us/step - loss: 8898.3723 - mse: 8898.3770 2s - loss: 8812.9383 -  - ETA: 1s - - ETA: 0s - loss: 8961.874\n",
      "Best: -8787.795777 using {'model__init_mode': 'glorot_uniform'}\n",
      "-9050.052618 (777.735861) with: {'model__init_mode': 'uniform'}\n",
      "-8962.128831 (946.072533) with: {'model__init_mode': 'normal'}\n",
      "-11007.294947 (843.683725) with: {'model__init_mode': 'zero'}\n",
      "-8914.576357 (701.921851) with: {'model__init_mode': 'glorot_normal'}\n",
      "-8787.795777 (633.583423) with: {'model__init_mode': 'glorot_uniform'}\n"
     ]
    }
   ],
   "source": [
    "init_mode = [\"uniform\", \"normal\",\"zero\",\"glorot_normal\",\"glorot_uniform\"]\n",
    "param_grid = dict(model__init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "grid_result = grid.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL MODEL\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, kernel_initializer=\"glorot_uniform\", activation=\"relu\", input_shape=(n_cols,)))\n",
    "    model.add(Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"linear\"))\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=optimizer, loss = 'mean_squared_error', metrics=[mse])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs=500, batch_size=5, verbose=2)\n",
    "final_model = Pipeline([(\"scale\", MinMaxScaler()),(\"model\", model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 5s - loss: 11075.0773 - mse: 11075.0635\n",
      "Epoch 2/500\n",
      " - 4s - loss: 10434.3489 - mse: 10434.3545\n",
      "Epoch 3/500\n",
      " - 3s - loss: 10137.1994 - mse: 10137.1982\n",
      "Epoch 4/500\n",
      " - 4s - loss: 9939.5530 - mse: 9939.5576\n",
      "Epoch 5/500\n",
      " - 4s - loss: 9835.1738 - mse: 9835.1758\n",
      "Epoch 6/500\n",
      " - 4s - loss: 9771.0881 - mse: 9771.0947\n",
      "Epoch 7/500\n",
      " - 4s - loss: 9712.3982 - mse: 9712.3984\n",
      "Epoch 8/500\n",
      " - 5s - loss: 9672.5989 - mse: 9672.6074\n",
      "Epoch 9/500\n",
      " - 4s - loss: 9619.4734 - mse: 9619.4629\n",
      "Epoch 10/500\n",
      " - 4s - loss: 9594.8808 - mse: 9594.8848\n",
      "...\n",
      "...\n",
      "...\n",
      "Epoch 490/500\n",
      " - 3s - loss: 8545.5179 - mse: 8545.5234\n",
      "Epoch 491/500\n",
      " - 4s - loss: 8548.5375 - mse: 8548.5352\n",
      "Epoch 492/500\n",
      " - 5s - loss: 8556.9566 - mse: 8556.9492\n",
      "Epoch 493/500\n",
      " - 3s - loss: 8556.1504 - mse: 8556.1504\n",
      "Epoch 494/500\n",
      " - 3s - loss: 8540.5815 - mse: 8540.5850\n",
      "Epoch 495/500\n",
      " - 3s - loss: 8545.8279 - mse: 8545.8262\n",
      "Epoch 496/500\n",
      " - 3s - loss: 8552.7196 - mse: 8552.7246\n",
      "Epoch 497/500\n",
      " - 3s - loss: 8553.2256 - mse: 8553.2246\n",
      "Epoch 498/500\n",
      " - 3s - loss: 8526.5336 - mse: 8526.5361\n",
      "Epoch 499/500\n",
      " - 3s - loss: 8544.1402 - mse: 8544.1328\n",
      "Epoch 500/500\n",
      " - 3s - loss: 8558.5630 - mse: 8558.5596\n"
     ]
    }
   ],
   "source": [
    "result = final_model.fit(X_train_outer, y_train_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse_score = result.score(X_train_outer, y_train_outer) * (-1)\n",
    "test_mse_score = result.score(X_test_outer, y_test_outer) * (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ERROR: 8470.90\n",
      "TEST ERROR: 8177.98\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING ERROR: %.2f\" % train_mse_score)\n",
    "print(\"TEST ERROR: %.2f\" % test_mse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test_outer\n",
    "y_pred = final_model.predict(X_test_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = mean_absolute_error(y_true, y_pred)\n",
    "test_mse = mean_squared_error(y_true, y_pred)\n",
    "test_rsquare = r2_score(y_true, y_pred)\n",
    "test_max = max_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:\n",
      "Mean squared error: 8177.984\n",
      "Mean absolute error: 47.415\n",
      "R-squared score: 0.218\n",
      "Maximum residual error: 945.965\n"
     ]
    }
   ],
   "source": [
    "print(\"RESULTS:\")\n",
    "print(\"Mean squared error: %.3f\" % (test_mse))\n",
    "print(\"Mean absolute error: %.3f\" % (test_mae))\n",
    "print(\"R-squared score: %.3f\" % (test_rsquare))\n",
    "print(\"Maximum residual error: %.3f\" % (test_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
